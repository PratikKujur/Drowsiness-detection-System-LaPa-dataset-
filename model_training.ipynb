{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom glob import glob\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers as L\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-08T16:04:13.602875Z","iopub.execute_input":"2022-12-08T16:04:13.603385Z","iopub.status.idle":"2022-12-08T16:04:13.609578Z","shell.execute_reply.started":"2022-12-08T16:04:13.603344Z","shell.execute_reply":"2022-12-08T16:04:13.608311Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"global image_h\nglobal image_w\nglobal num_landmarks\n","metadata":{"execution":{"iopub.status.busy":"2022-12-08T16:04:13.616297Z","iopub.execute_input":"2022-12-08T16:04:13.616629Z","iopub.status.idle":"2022-12-08T16:04:13.627304Z","shell.execute_reply.started":"2022-12-08T16:04:13.616597Z","shell.execute_reply":"2022-12-08T16:04:13.626408Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"   \"\"\" Hyperparameters \"\"\"\nimage_h = 256\nimage_w = 256\nnum_landmarks = 106\ninput_shape = (image_h, image_w, 3)\nbatch_size = 32\nlr = 1e-3\nnum_epochs = 1","metadata":{"execution":{"iopub.status.busy":"2022-12-08T16:04:13.640868Z","iopub.execute_input":"2022-12-08T16:04:13.641158Z","iopub.status.idle":"2022-12-08T16:04:13.646651Z","shell.execute_reply.started":"2022-12-08T16:04:13.641113Z","shell.execute_reply":"2022-12-08T16:04:13.645587Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"dataset_path=\"/kaggle/input/lp-dataset/LaPa/LaPa\"\nmodel_path=\"//kaggle/working/model.h5\"\ncsv_path=\"/kaggle/working//data.csv\"","metadata":{"execution":{"iopub.status.busy":"2022-12-08T16:04:13.648718Z","iopub.execute_input":"2022-12-08T16:04:13.649866Z","iopub.status.idle":"2022-12-08T16:04:13.658177Z","shell.execute_reply.started":"2022-12-08T16:04:13.649829Z","shell.execute_reply":"2022-12-08T16:04:13.657246Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def load_dataset(path):\n    train_x = sorted(glob('/kaggle/input/lp-dataset/LaPa/LaPa/train/images/*.jpg'))\n    train_y = sorted(glob('/kaggle/input/lp-dataset/LaPa/LaPa/train/landmarks/*.txt'))\n\n    valid_x = sorted(glob('/kaggle/input/lp-dataset/LaPa/LaPa/val/images/*.jpg'))\n    valid_y = sorted(glob('/kaggle/input/lp-dataset/LaPa/LaPa/val/landmarks/*.txt'))\n\n    test_x = sorted(glob('/kaggle/input/lp-dataset/LaPa/LaPa/test/images/*.jpg'))\n    test_y = sorted(glob('/kaggle/input/lp-dataset/LaPa/LaPa/test/landmarks/*.txt'))  \n    \n    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-08T16:04:13.670784Z","iopub.execute_input":"2022-12-08T16:04:13.671614Z","iopub.status.idle":"2022-12-08T16:04:13.678007Z","shell.execute_reply.started":"2022-12-08T16:04:13.671575Z","shell.execute_reply":"2022-12-08T16:04:13.677181Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def read_image_lankmarks(image_path, landmark_path):\n    \"\"\" Image \"\"\"\n    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    h, w, _ = image.shape\n    image = cv2.resize(image, (256, 256))\n    image = image/255.0\n    image = image.astype(np.float32)\n    data = open(landmark_path, \"r\").read()\n    lankmarks = []\n    \n    for line in data.strip().split(\"\\n\")[1:]:\n        x, y = line.split(\" \")\n        x = float(x)/w\n        y = float(y)/h  \n        \n        lankmarks.append(x)\n        lankmarks.append(y)\n    \n    lankmarks = np.array(lankmarks, dtype=np.float32)\n        \n    return image, lankmarks   ","metadata":{"execution":{"iopub.status.busy":"2022-12-08T16:04:13.682352Z","iopub.execute_input":"2022-12-08T16:04:13.683094Z","iopub.status.idle":"2022-12-08T16:04:13.693444Z","shell.execute_reply.started":"2022-12-08T16:04:13.683063Z","shell.execute_reply":"2022-12-08T16:04:13.692200Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def preprocess(x, y):\n    def f(x, y):\n        x = x.decode()\n        y = y.decode()\n\n        image, landmarks = read_image_lankmarks(x, y)\n        return image, landmarks\n\n    image, landmarks = tf.numpy_function(f, [x, y], [tf.float32, tf.float32])\n    image.set_shape([256,256, 3])\n    landmarks.set_shape([106 * 2])\n\n    return image, landmarks","metadata":{"execution":{"iopub.status.busy":"2022-12-08T16:04:13.711310Z","iopub.execute_input":"2022-12-08T16:04:13.711959Z","iopub.status.idle":"2022-12-08T16:04:13.718964Z","shell.execute_reply.started":"2022-12-08T16:04:13.711920Z","shell.execute_reply":"2022-12-08T16:04:13.717843Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"def tf_dataset(x, y, batch=8):\n    ds = tf.data.Dataset.from_tensor_slices((x, y))\n    ds = ds.shuffle(buffer_size=5000).map(preprocess)\n    ds = ds.batch(batch).prefetch(2)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-12-08T16:04:13.801230Z","iopub.execute_input":"2022-12-08T16:04:13.801563Z","iopub.status.idle":"2022-12-08T16:04:13.809688Z","shell.execute_reply.started":"2022-12-08T16:04:13.801535Z","shell.execute_reply":"2022-12-08T16:04:13.808434Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"def build_model(input_shape, num_landmarks):\n    inputs = L.Input(input_shape)\n\n    backbone = MobileNetV2(include_top=False, weights=\"imagenet\", input_tensor=inputs, alpha=0.5)\n    backbone.trainable = True\n\n    x = backbone.output\n    x = L.GlobalAveragePooling2D()(x)\n    x = L.Dropout(0.2)(x)\n    outputs = L.Dense(num_landmarks*2, activation=\"sigmoid\")(x)\n\n    model = tf.keras.models.Model(inputs, outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-08T16:04:13.830474Z","iopub.execute_input":"2022-12-08T16:04:13.831162Z","iopub.status.idle":"2022-12-08T16:04:13.838457Z","shell.execute_reply.started":"2022-12-08T16:04:13.831098Z","shell.execute_reply":"2022-12-08T16:04:13.837337Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    \"\"\" Seeding \"\"\"\n    np.random.seed(42)\n    tf.random.set_seed(42)\n\n    \"\"\" Directory for storing files \"\"\"\n   \n    \"\"\" Hyperparameters \"\"\"\n   \n\n    \"\"\" Paths \"\"\"\n  \n\n    \"\"\" Loading the dataset \"\"\"\n    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n    print(f\"Train: {len(train_x)}/{len(train_y)} - Valid: {len(valid_x)}/{len(valid_y)} - Test: {len(test_x)}/{len(test_x)}\")\n    print(\"\")\n\n    \"\"\" Dataset Pipeline \"\"\"\n    train_ds = tf_dataset(train_x, train_y, batch=batch_size)\n    valid_ds = tf_dataset(valid_x, valid_y, batch=batch_size)\n\n    \"\"\" Model \"\"\"\n    model = build_model(input_shape, num_landmarks)\n    model.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(lr),metrics=[\"mae\",\"accuracy\"])\n\n    \"\"\" Training \"\"\"\n    callbacks = [\n        ModelCheckpoint(model_path, verbose=1, save_best_only=True, monitor='val_loss'),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n        CSVLogger(csv_path, append=True),\n        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n    ]\n\n    model.fit(train_ds,\n        validation_data=valid_ds,\n        epochs=num_epochs,\n        callbacks=callbacks\n    )","metadata":{"execution":{"iopub.status.busy":"2022-12-08T16:04:13.842916Z","iopub.execute_input":"2022-12-08T16:04:13.843692Z","iopub.status.idle":"2022-12-08T16:08:41.388357Z","shell.execute_reply.started":"2022-12-08T16:04:13.843650Z","shell.execute_reply":"2022-12-08T16:08:41.387214Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Train: 18168/18168 - Valid: 2000/2000 - Test: 2000/2000\n\n568/568 [==============================] - 242s 418ms/step - loss: 0.6564 - mae: 0.0235 - accuracy: 0.3212 - val_loss: 1.6217 - val_mae: 0.2973 - val_accuracy: 0.4070\n\nEpoch 00001: val_loss improved from inf to 1.62170, saving model to //kaggle/working/model.h5\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-12-08T16:08:41.391017Z","iopub.execute_input":"2022-12-08T16:08:41.391796Z","iopub.status.idle":"2022-12-08T16:08:41.894304Z","shell.execute_reply.started":"2022-12-08T16:08:41.391752Z","shell.execute_reply":"2022-12-08T16:08:41.893257Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}